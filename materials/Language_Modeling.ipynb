{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Некоторые задания в этой тетрадки были созданы на основе соотвествующей тетрадки курса NLP от Elena Voita."
      ],
      "metadata": {
        "id": "K7c0vMPN8gWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Генерация текста: н-граммы\n",
        "\n",
        "В этой тетрадке мы научимся делать простую модель генерации текста на основе н-грамм и встречаемости в корпусе."
      ],
      "metadata": {
        "id": "_pjlNnOv4Ut4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nlpXQYlpuwmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "TcWFfFlLgb1r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем пробовать генерировать шутки. Для обучения будем использовать [датасет с постами reddit](https://kaggle.com/datasets/thedevastator/one-million-reddit-jokes)."
      ],
      "metadata": {
        "id": "1WT4GhNjvba0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = # YOUR_PATH\n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "2VJz6GMP1nNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "xDqSNS4s_tXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как наша задача генерации требует только текста, оставим только соответствующий столбец."
      ],
      "metadata": {
        "id": "QSHwGZ-S3t-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['selftext']\n",
        "data = data[columns]"
      ],
      "metadata": {
        "id": "Sg3r3lQI16CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка данных\n",
        "###1. Чистка датасета\n",
        "Для начала нужно определиться, есть в данных пропуски, и избавиться от них, если есть.\n",
        "\n",
        "__Подсказка:__ Часто пропуски они обозначаются как nan, но иногда можно заметить иные способы."
      ],
      "metadata": {
        "id": "edTMfW2Z6lBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR CODE HERE> #"
      ],
      "metadata": {
        "id": "8pI_AuFN6jqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Надо тексты привести к нижнему регистру. Пунктуацию можно оставить, так как она влияет на смысл предложения и на встречаемость.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы. При делении текста на слова, используйте word_tokenize."
      ],
      "metadata": {
        "id": "dQ3V-peRAg3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import re"
      ],
      "metadata": {
        "id": "ZMjEpki3VmC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text: str) -> list:\n",
        "     '''\n",
        "     Делит текст на слова и пунктуацию и приводит все к нижнему регистру\n",
        "     :param text: строка\n",
        "     :returns: список слов и знаков препинания\n",
        "     '''\n",
        "     # <YOUR CODE HERE> #\n",
        "     return"
      ],
      "metadata": {
        "id": "DbSc8NqvUq-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['words'] = data['selftext'].apply(clean_text)\n",
        "data['lens'] = data['words'].apply(len)\n",
        "data = data[data.lens > 3]"
      ],
      "metadata": {
        "id": "ckQKt8tI_prG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = data['words'].tolist()"
      ],
      "metadata": {
        "id": "3htMqxgaCLmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAjsJvvwT_t1",
        "outputId": "7131f4a2-8e2e-41b4-bd02-167744db3147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['my',\n",
              "  'corona',\n",
              "  'is',\n",
              "  'covered',\n",
              "  'with',\n",
              "  'foreskin',\n",
              "  'so',\n",
              "  'it',\n",
              "  'is',\n",
              "  'not',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'viruses',\n",
              "  '.'],\n",
              " [\"it's\", 'called', 'google', 'sheets', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams\n",
        "Для начала попробуем создать самую простую модель, основанную на встречаемости н-граммы в корпусе."
      ],
      "metadata": {
        "id": "MUp_9FzUW3Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "mP00Mb3MlMeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS = '[bos]', '[eos]'\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, lines, n):\n",
        "        assert n >= 1\n",
        "        self.n = n\n",
        "        counts = self.ngram_counts(lines, self.n)\n",
        "\n",
        "        # перевести количества в вероятности\n",
        "        self.probs = defaultdict(Counter)\n",
        "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
        "        # <YOUR CODE HERE> #\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        \"\"\"\n",
        "        :param prefix: строка запроса\n",
        "        :returns: словарь с возможными продолжениями заданного префикса\n",
        "        \"\"\"\n",
        "        prefix = prefix.split()\n",
        "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
        "        prefix = [ BOS ] * (self.n - 1 - len(prefix)) + prefix\n",
        "        return self.probs[tuple(prefix)]\n",
        "\n",
        "    @staticmethod\n",
        "    def ngram_counts(lines: list, n: int) -> dict:\n",
        "        '''\n",
        "        Создаёт словарь, где каждому префиксу (n-1 слово) присваивается словарь,\n",
        "        в котором ключи - слова, а значения - количество н-грамм в текстах\n",
        "        :param lines: список списков\n",
        "        :param n: количество слов в н-грамме\n",
        "        :returns: словарь, в котором для каждого в префикса известно количество\n",
        "        н-грамм с каждым словом\n",
        "        '''\n",
        "        dictionary = defaultdict(Counter)\n",
        "        # dictionary[(word1, word2)][word3] = count((word1, word2, word3))\n",
        "        # <YOUR CODE HERE> #\n",
        "        return dictionary\n",
        "\n",
        "# Проверим работу функции ngram_counts\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = NGramLanguageModel.ngram_counts(dummy_lines, n=3)\n",
        "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "assert len(dummy_counts[(BOS, BOS)]) == 66\n",
        "assert dummy_counts[BOS, 'a']['melon'] == 1\n",
        "\n",
        "# Проверим работу модели\n",
        "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
        "p_initial = dummy_lm.get_possible_next_tokens('')\n",
        "assert p_initial.most_common(1)[0][0] == 'a'"
      ],
      "metadata": {
        "id": "EQQpVdxSBahu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Попробуем составить предложение используя жадный метод."
      ],
      "metadata": {
        "id": "v96is9vGawaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm: NGramLanguageModel, prefix: str) -> str:\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    # <YOUR CODE HERE> #\n",
        "    return # next word"
      ],
      "metadata": {
        "id": "5p4C8r0TP-jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "YcIeQluWfJ-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, prefix)\n",
        "while word != EOS:\n",
        "    prefix += f' {word}'\n",
        "    word = get_next_word(lm, prefix)\n",
        "\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "id": "rh9oYWyosfnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Выбор наиболее вероятного слова не показал хороших результатов. Тем более, он будет строить очень много похожих предложений, а нам хочется разнообразия. Давайте попробуем семплировать методом top-k: выбираем k наиболее встречаемых вариантов и из них выбираем один случайным образом."
      ],
      "metadata": {
        "id": "euWO6e9hTRkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm: NGramLanguageModel, prefix: str, k:int) -> str:\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :param k: количество слов в top-k\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    # <YOUR CODE HERE> #\n",
        "    return # next word"
      ],
      "metadata": {
        "id": "YlQNWIZrS-aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for i in range(repeat):\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "gUlsfNObToqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, '', 5)\n",
        "while word != EOS:\n",
        "    prefix += f'{word} '\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "id": "nkBhxv88Ts0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Для сравнения можно сделать beam search. Напоминаем, что он на каждом шаге выбирает k наилучших вариантов - те, с которыми наибольшая вероятность всего предложения. Кроме этого надо не забыть, что мы переводим вероятности в логарифмы: таким образом считается сумма логарифмов вероятностей для каждой н-граммы, из которого состоит предложение.\n",
        "Чтобы не пересчитывать каждый раз корпус, давайте будем считать вероятность последней н-граммы.\n",
        "\n",
        "Попробуйте написать свой beam search, для n-gramm, где n=3 и для k=2."
      ],
      "metadata": {
        "id": "HC5axKpqtcvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "        \\frac{1}{L^\\alpha}\\sum_{t'=1}^LlogP(y_{t'}|y_{t'-n}, ..., y_{t'-1})\n",
        "    \\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "E3ceW1U7GPlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'he' # YOUR IDEA\n",
        "prefixes = [prefix, prefix]\n",
        "probs = [0, 0]\n",
        "k = 2\n",
        "\n",
        "# <YOUR CODE HERE> #"
      ],
      "metadata": {
        "id": "SetLttedXIKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценивание модели\n",
        "Раз мы научились делать простую языковую модель, надо понять, насколько она хорошо описывает язык. Для оценивания этого используем перплексию.\n",
        "\n",
        "$PPL(W) = e^{ln(P(W)^{-\\frac{1}{N}})} =e^{{-\\frac{1}{N}}ln(P(W))}$\n",
        "\n"
      ],
      "metadata": {
        "id": "D71N55ESiJav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Для начала нужно разделить данные на тренировочные и тестовые"
      ],
      "metadata": {
        "id": "Vos4iA5mofJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(data['words'], train_size=0.8)"
      ],
      "metadata": {
        "id": "PtnXGWswob2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Давайте напишем функцию, которая будет считать перплексию для каждого отдельного предложения на основе n-грамм. Для каждой нграммы считается её вероятность. Нам её считать не надо, так как она уже записана в атрибуте _self.probs_ в нашем классе модели."
      ],
      "metadata": {
        "id": "2HDDyuiPonKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(model: NGramLanguageModel, text: list, n=1) -> float:\n",
        "    \"\"\"\n",
        "    :param model: language model\n",
        "    :param text: список н-грамм предложения\n",
        "    :param n: количество слов в н-грамме\n",
        "    :returns: значение перплексии одного предложения\n",
        "    \"\"\"\n",
        "    # <YOUR CODE HERE> #\n",
        "    return"
      ],
      "metadata": {
        "id": "wYUka8tVoqZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Теперь можем посчитать среднюю перплексию по всему датасету."
      ],
      "metadata": {
        "id": "RtiVA2fWqAri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "lm = NGramLanguageModel(X_train, n=n)\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=n))\n",
        "    value = perplexity(lm, test_sent, n=n)\n",
        "    avg_ppl += value\n",
        "\n",
        "avg_ppl /=  len(X_test)\n",
        "assert np.isclose(avg_ppl, 1857.90, atol=1e-1)\n",
        "print(avg_ppl)"
      ],
      "metadata": {
        "id": "6nbtX8nbqA_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем теперь сравнить перплексию для моделей униграм, биграм и триграм. Почему результаты получились такие?"
      ],
      "metadata": {
        "id": "TnNeiymmI0Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR CODE HERE> #"
      ],
      "metadata": {
        "id": "VGhyfsiaJiLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Использование готовых инструментов\n",
        "К счастью, нам всё писать необязательно. Необходимые функции и модули уже были написаны умными программистами. Давайте посмотрим на модуль nltk и на то, что он нам предлагает."
      ],
      "metadata": {
        "id": "huzgWYb7nmlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "\n",
        "n = 1\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)"
      ],
      "metadata": {
        "id": "r8OKwq9ql94P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    # <YOUR CODE HERE> #\n",
        "    pass"
      ],
      "metadata": {
        "id": "-J32Wf2Km6Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте повторим то же самое но с моделями на биграммах и триграммах. Сравните результаты. Почему они такие?"
      ],
      "metadata": {
        "id": "psvTMTHfnUMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR CODE HERE> #"
      ],
      "metadata": {
        "id": "otWeiZuMneYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "И давайте напоследок попробуем сгенерировать последовательность с помощью обученной модели:"
      ],
      "metadata": {
        "id": "-ln4Th3ZKUiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(20, text_seed=['he'])"
      ],
      "metadata": {
        "id": "c2_FOjwAKbW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {
        "id": "zCm30Mgf56Cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Решение"
      ],
      "metadata": {
        "id": "u3FtFBmg58KP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка данных\n",
        "###1. Чистка датасета\n",
        "\n",
        "Для начала надо избавиться от пустых строк, или же нанов. Часто они обозначаются как nan, но иногда можно заметить иные способы."
      ],
      "metadata": {
        "id": "qT2oie9T53nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/NLP_manual/Datasets/reddit_jokes.csv'\n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "CRIUkZFEspXF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "IFo2Opm9spXG",
        "outputId": "8490bff6-8921-4390-ee77-7c90cac21141"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type      id subreddit.id subreddit.name  subreddit.nsfw  created_utc  \\\n",
              "0  post  ftbp1i        2qh72          jokes           False   1585785543   \n",
              "1  post  ftboup        2qh72          jokes           False   1585785522   \n",
              "2  post  ftbopj        2qh72          jokes           False   1585785508   \n",
              "3  post  ftbnxh        2qh72          jokes           False   1585785428   \n",
              "4  post  ftbjpg        2qh72          jokes           False   1585785009   \n",
              "\n",
              "                                           permalink      domain  url  \\\n",
              "0  https://old.reddit.com/r/Jokes/comments/ftbp1i...  self.jokes  NaN   \n",
              "1  https://old.reddit.com/r/Jokes/comments/ftboup...  self.jokes  NaN   \n",
              "2  https://old.reddit.com/r/Jokes/comments/ftbopj...  self.jokes  NaN   \n",
              "3  https://old.reddit.com/r/Jokes/comments/ftbnxh...  self.jokes  NaN   \n",
              "4  https://old.reddit.com/r/Jokes/comments/ftbjpg...  self.jokes  NaN   \n",
              "\n",
              "                                            selftext  \\\n",
              "0  My corona is covered with foreskin so it is no...   \n",
              "1                         It's called Google Sheets.   \n",
              "2  The vacuum doesn't snore after sex.\\r\\n\\r\\n&am...   \n",
              "3                                          [removed]   \n",
              "4                                          [removed]   \n",
              "\n",
              "                                               title  score  \n",
              "0               I am soooo glad I'm not circumcised!      2  \n",
              "1  Did you know Google now has a platform for rec...      9  \n",
              "2  What is the difference between my wife and my ...     15  \n",
              "3                              My last joke for now.      9  \n",
              "4              The Nintendo 64 turns 18 this week...    134  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-617cf0bf-8300-469e-afb6-ecf1d20d9e67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit.id</th>\n",
              "      <th>subreddit.name</th>\n",
              "      <th>subreddit.nsfw</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>permalink</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>selftext</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbp1i</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785543</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbp1i...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My corona is covered with foreskin so it is no...</td>\n",
              "      <td>I am soooo glad I'm not circumcised!</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>post</td>\n",
              "      <td>ftboup</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785522</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftboup...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It's called Google Sheets.</td>\n",
              "      <td>Did you know Google now has a platform for rec...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbopj</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785508</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbopj...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The vacuum doesn't snore after sex.\\r\\n\\r\\n&amp;am...</td>\n",
              "      <td>What is the difference between my wife and my ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbnxh</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785428</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbnxh...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>My last joke for now.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbjpg</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785009</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbjpg...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>The Nintendo 64 turns 18 this week...</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-617cf0bf-8300-469e-afb6-ecf1d20d9e67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-617cf0bf-8300-469e-afb6-ecf1d20d9e67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-617cf0bf-8300-469e-afb6-ecf1d20d9e67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca705ec7-bdfc-4837-81ef-94bedad291a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca705ec7-bdfc-4837-81ef-94bedad291a0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca705ec7-bdfc-4837-81ef-94bedad291a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['selftext']]"
      ],
      "metadata": {
        "id": "Ewfm3u0espXG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OkC8R2BCB-bg",
        "outputId": "994750f9-a85b-4e12-9fb4-edc7da0447f9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 selftext\n",
              "0       My corona is covered with foreskin so it is no...\n",
              "1                              It's called Google Sheets.\n",
              "2       The vacuum doesn't snore after sex.\\r\\n\\r\\n&am...\n",
              "3                                               [removed]\n",
              "4                                               [removed]\n",
              "...                                                   ...\n",
              "999993  *zyan malik or whatever leaves 1d.  \\r\\n*Kayne...\n",
              "999994                                          [deleted]\n",
              "999995                                       I'll be Bach\n",
              "999996  So a moth goes into a podiatrists office.\\r\\n\\...\n",
              "999997                                          [deleted]\n",
              "\n",
              "[999998 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7143ef39-bb03-4379-8f71-5d7596b2f50a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My corona is covered with foreskin so it is no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's called Google Sheets.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The vacuum doesn't snore after sex.\\r\\n\\r\\n&amp;am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[removed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[removed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999993</th>\n",
              "      <td>*zyan malik or whatever leaves 1d.  \\r\\n*Kayne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999994</th>\n",
              "      <td>[deleted]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>I'll be Bach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>So a moth goes into a podiatrists office.\\r\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>[deleted]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999998 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7143ef39-bb03-4379-8f71-5d7596b2f50a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7143ef39-bb03-4379-8f71-5d7596b2f50a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7143ef39-bb03-4379-8f71-5d7596b2f50a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1548d92d-c427-447a-b81c-c4454e9a2ea3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1548d92d-c427-447a-b81c-c4454e9a2ea3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1548d92d-c427-447a-b81c-c4454e9a2ea3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['selftext'].value_counts()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea2c1ef-85d0-4006-8f27-c7ec4493ecf1",
        "id": "1BjPfU-S53nO"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[removed]                          232919\n",
              "[deleted]                          188442\n",
              "\\[removed\\]                           272\n",
              "To get to the other side.             125\n",
              "Dr. Dre                               111\n",
              "A stick.                               83\n",
              "None.                                  81\n",
              "A stick                                76\n",
              "He worked it out with a pencil.        74\n",
              "Then it hit me.                        72\n",
              "Name: selftext, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно заметить, что наиболее частым классом являются _removed_ или _deleted_."
      ],
      "metadata": {
        "id": "ldpt6ruF53nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Размер данных до чистки', data.shape)\n",
        "data = data[~data.isin(['[removed]', '[deleted]', '\\[removed\\]', 'removed', 'deleted'])]\n",
        "data = data.dropna()\n",
        "print('Размер данных после чистки', data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3271e972-b00d-4f90-dc45-871c4a37545b",
        "id": "DR50a_Lq53nO"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер данных до чистки (999998, 1)\n",
            "Размер данных после чистки (573887, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Надо тексты привести к нижнему регистру и убрать пунктуацию.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы. При делении текста на слова, используйте word_tokenize."
      ],
      "metadata": {
        "id": "xI6azkP553nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "C55KqII853nP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "     text = text.lower()\n",
        "     new_text = []\n",
        "     for word in word_tokenize(text):\n",
        "        new_text.append(word)\n",
        "     return new_text"
      ],
      "metadata": {
        "id": "Kt8xbpeAE7yZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['words'] = data['selftext'].apply(clean_text)\n",
        "data['lens'] = data['words'].apply(len)\n",
        "data = data[data.lens > 3]"
      ],
      "metadata": {
        "id": "-l96PkDv53nP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = data['words'].tolist()"
      ],
      "metadata": {
        "id": "MKbpYrvJ53nP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876558d6-f90b-456f-d3db-fad799fa632c",
        "id": "CKmViv5G53nP"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['my',\n",
              "  'corona',\n",
              "  'is',\n",
              "  'covered',\n",
              "  'with',\n",
              "  'foreskin',\n",
              "  'so',\n",
              "  'it',\n",
              "  'is',\n",
              "  'not',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'viruses',\n",
              "  '.'],\n",
              " ['it', \"'s\", 'called', 'google', 'sheets', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams\n",
        "Для начала попробуем создать самую простую модель, основанную на встречаемости н-граммы в корпусе."
      ],
      "metadata": {
        "id": "wLqrE_jq53nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "BjxFUMET53nP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS = '[bos]', '[eos]'\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, lines, n):\n",
        "        assert n >= 1\n",
        "        self.n = n\n",
        "        counts = self.ngram_counts(lines, self.n)\n",
        "\n",
        "        # перевести количества в вероятности\n",
        "        self.probs = defaultdict(Counter)\n",
        "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
        "\n",
        "        for key, value in counts.items():\n",
        "            sum_of_prefix = sum(value.values())\n",
        "            for word, cnts in value.items():\n",
        "                self.probs[key][word] = cnts / sum_of_prefix\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        \"\"\"\n",
        "        :param prefix: строка запроса\n",
        "        :returns: словарь с возможными продолжениями заданного префикса\n",
        "        \"\"\"\n",
        "        prefix = prefix.split()\n",
        "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
        "        prefix = [ BOS ] * (self.n - 1 - len(prefix)) + prefix\n",
        "        return self.probs[tuple(prefix)]\n",
        "\n",
        "    @staticmethod\n",
        "    def ngram_counts(lines, n):\n",
        "        dictionary = defaultdict(Counter)\n",
        "        for line in lines:\n",
        "            new_line = [BOS] * (n-1) + line + [EOS]\n",
        "            for i in range(n-1, len(new_line)):\n",
        "                prefix = tuple(new_line[i-n+1:i])\n",
        "                word = new_line[i]\n",
        "                dictionary[prefix][word] += 1\n",
        "        return dictionary\n",
        "\n",
        "# Проверим работу функции ngram_counts\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = NGramLanguageModel.ngram_counts(dummy_lines, n=3)\n",
        "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "assert len(dummy_counts[(BOS, BOS)]) == 59\n",
        "assert dummy_counts[BOS, 'a']['melon'] == 1\n",
        "\n",
        "# Проверим работу модели\n",
        "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
        "p_initial = dummy_lm.get_possible_next_tokens('')\n",
        "assert p_initial.most_common(1)[0][0] == 'a'"
      ],
      "metadata": {
        "id": "2BhgtJdoNh2i"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Жадный метод."
      ],
      "metadata": {
        "id": "C7qBxszJ53nQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm, prefix):\n",
        "    return lm.get_possible_next_tokens(prefix).most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "M4qpcfyH53nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "VTAtUgCjNwxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2c5233-a0b1-49cd-b166-057770de6310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get off the roof . [eos]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Top-k."
      ],
      "metadata": {
        "id": "fL_93t6753nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm, prefix, k):\n",
        "    next_words = lm.get_possible_next_tokens(prefix).most_common(k)\n",
        "    index = random.randint(0, min(k, len(next_words))-1)\n",
        "    return next_words[index][0]"
      ],
      "metadata": {
        "id": "acwYCEJe53nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word(lm, prefix, k=5)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "wI2ODnJCN1SV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb87d32-22b8-4a82-bc41-909daa32fdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get a divorce . the man replies : - ) ) [eos]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, prefix, k=5)\n",
        "while word != EOS:\n",
        "    prefix += f' {word}'\n",
        "    word = get_next_word(lm, prefix, k=5)\n",
        "\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "id": "o-rWLLT6N1SW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74abd595-e9b0-4b5c-976c-ab6425e1dca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " he was in my pocket and the bartender , who is a little bit of time . he says to the doctor .[eos] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Beam search"
      ],
      "metadata": {
        "id": "fOgqjZl653nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'he' # YOUR IDEA\n",
        "prefixes = [prefix, prefix]\n",
        "probs = [0, 0]\n",
        "k = 2\n",
        "\n",
        "step = 1\n",
        "max_step = 20\n",
        "while (not prefixes[0].endswith(EOS)) and (not prefixes[1].endswith(EOS)) and (step != max_step):\n",
        "    print('step', step)\n",
        "    print(prefixes, probs, sep='\\n')\n",
        "    step += 1\n",
        "    for prefix in prefixes:\n",
        "        possible_words1 = lm.get_possible_next_tokens(prefixes[0]).most_common(k)\n",
        "    probs1 = []\n",
        "    for word in possible_words1:\n",
        "        probs1.append((word[0], probs[0]+np.log(word[1])))\n",
        "    possible_words2 = lm.get_possible_next_tokens(prefixes[1]).most_common(k)\n",
        "    probs2 = []\n",
        "    for word in possible_words2:\n",
        "        probs2.append((word[0], probs[0]+np.log(word[1])))\n",
        "    choice = []\n",
        "    probs1 = sorted(probs1, key=lambda x: x[1], reverse=True)\n",
        "    probs2 = sorted(probs2, key=lambda x: x[1], reverse=True)\n",
        "    probs_new = []\n",
        "    while len(choice) != k and len(probs1) != 0 and len(probs2) != 0:\n",
        "        if probs1[0][1] > probs2[0][1]:\n",
        "            choice.append(prefixes[0] + f' {probs1[0][0]}')\n",
        "            probs_new.append(probs1[0][1])\n",
        "            probs1 = probs1[1:]\n",
        "            possible_words1 = probs1[1:]\n",
        "        else:\n",
        "            choice.append(prefixes[1] + f' {probs2[0][0]}')\n",
        "            probs_new.append(probs2[0][1])\n",
        "            probs2 = probs2[1:]\n",
        "            possible_words2 = probs2[1:]\n",
        "    prefixes = choice\n",
        "    probs = probs_new"
      ],
      "metadata": {
        "id": "lMpqMOsk53nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b64314e-c6a1-435e-9136-e637a56492af"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1\n",
            "['he', 'he']\n",
            "[0, 0]\n",
            "step 2\n",
            "['he was', 'he was']\n",
            "[-2.043168321757178, -2.043168321757178]\n",
            "step 3\n",
            "['he was a', 'he was a']\n",
            "[-4.454801801110815, -4.454801801110815]\n",
            "step 4\n",
            "['he was a little', 'he was a little']\n",
            "[-7.675854929925643, -7.675854929925643]\n",
            "step 5\n",
            "['he was a little bit', 'he was a little bit']\n",
            "[-10.395961661061712, -10.395961661061712]\n",
            "step 6\n",
            "['he was a little bit of', 'he was a little bit of']\n",
            "[-11.900688619406782, -11.900688619406782]\n",
            "step 7\n",
            "['he was a little bit of a', 'he was a little bit of a']\n",
            "[-13.038863029384936, -13.038863029384936]\n",
            "step 8\n",
            "['he was a little bit of a sudden', 'he was a little bit of a sudden']\n",
            "[-15.411522464771627, -15.411522464771627]\n",
            "step 9\n",
            "['he was a little bit of a sudden ,', 'he was a little bit of a sudden ,']\n",
            "[-16.548124457982478, -16.548124457982478]\n",
            "step 10\n",
            "['he was a little bit of a sudden , the', 'he was a little bit of a sudden , a']\n",
            "[-17.978663520900128, -17.978663520900128]\n",
            "step 11\n",
            "['he was a little bit of a sudden , the man', 'he was a little bit of a sudden , a man']\n",
            "[-20.56560589358449, -21.33783981183231]\n",
            "step 12\n",
            "['he was a little bit of a sudden , a man walks', 'he was a little bit of a sudden , the man says']\n",
            "[-23.03385365738585, -23.228489929142913]\n",
            "step 13\n",
            "['he was a little bit of a sudden , a man walks into', 'he was a little bit of a sudden , the man says ,']\n",
            "[-23.730251363213245, -23.992913256854983]\n",
            "step 14\n",
            "['he was a little bit of a sudden , the man says , ``', 'he was a little bit of a sudden , a man walks into a']\n",
            "[-24.077685385451378, -24.104075537433896]\n",
            "step 15\n",
            "['he was a little bit of a sudden , a man walks into a bar', 'he was a little bit of a sudden , the man says , `` i']\n",
            "[-25.313389811443358, -26.018323561853975]\n",
            "step 16\n",
            "['he was a little bit of a sudden , a man walks into a bar and', 'he was a little bit of a sudden , a man walks into a bar .']\n",
            "[-26.65497058546184, -26.711125688291567]\n",
            "step 17\n",
            "['he was a little bit of a sudden , a man walks into a bar . the', 'he was a little bit of a sudden , a man walks into a bar and orders']\n",
            "[-28.068122557197157, -28.63644866089873]\n",
            "step 18\n",
            "['he was a little bit of a sudden , a man walks into a bar and orders a', 'he was a little bit of a sudden , a man walks into a bar . the man']\n",
            "[-28.620080806844136, -30.564029597580426]\n",
            "step 19\n",
            "['he was a little bit of a sudden , a man walks into a bar and orders a drink', 'he was a little bit of a sudden , a man walks into a bar and orders a beer']\n",
            "[-30.00418458658421, -30.147453766223933]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценивание модели\n",
        "Раз мы научились делать простую языковую модель, надо понять, насколько она хорошо описывает язык. Для оценивания этого используем перплексию.\n",
        "\n",
        "$PPL(W) = e^{ln(P(W)^{-\\frac{1}{N}})} =e^{{-\\frac{1}{N}}ln(P(W))}$\n",
        "\n",
        "1. Для начала нужно разделить данные на тренировочные и тестовые"
      ],
      "metadata": {
        "id": "UHFl8O7ltwC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(data['words'], train_size=0.8)"
      ],
      "metadata": {
        "id": "TEQnJLYNIL3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Давайте напишем функцию, которая будет считать перплексию для каждого отдельного предложения на основе n-грамм. Для каждой нграммы считается её вероятность. Нам её считать не надо, так как она уже записана в атрибуте _self.probs_ в нашем классе модели."
      ],
      "metadata": {
        "id": "jdDa0pPqK4Do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(model, text, n=1):\n",
        "    result = 0\n",
        "    length = 0\n",
        "    for ngram in text:\n",
        "        if n == 1:\n",
        "            prefix = ()\n",
        "        else:\n",
        "            prefix = ngram[:n-1]\n",
        "        prob = model.probs[prefix][ngram[-1]]\n",
        "        if prob != 0:\n",
        "            result += np.log2(prob)\n",
        "        length += 1\n",
        "    enthropy = - (result / length)\n",
        "    return 2**enthropy"
      ],
      "metadata": {
        "id": "IZfQ0es9M28g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Теперь можем посчитать среднюю перплексию по всему датасету."
      ],
      "metadata": {
        "id": "3MIWhGDSK4Do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "lm = NGramLanguageModel(X_train, n=1)\n",
        "all_ppls_my = []\n",
        "avg_ppl_my = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=1))\n",
        "    value = perplexity(lm, test_sent, 1)\n",
        "    all_ppls_my.append((' '.join(sentence), value))\n",
        "    avg_ppl_my += value\n",
        "print(avg_ppl_my / len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfvtCERTKUrB",
        "outputId": "019d481e-1702-4ca7-a5ed-5b96f9fc8f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1857.8977933685876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = sorted(all_ppls_my, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C67eGgFlSpYS",
        "outputId": "ab2e15ec-fcb8-4d12-a816-fdb5cf910553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('chs chsa rel smoth', 1.0) ('tak tak tak tak tak tak', 18871163.000000067)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем теперь сравнить перплексию для моделей униграм, биграм и триграм. Почему результаты получились такие?"
      ],
      "metadata": {
        "id": "qqWmZTneK8ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(X_train, n=2)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=2))\n",
        "    value = perplexity(lm, test_sent, 2)\n",
        "    all_ppls.append((' '.join(sentence), value))\n",
        "    avg_ppl += value\n",
        "print(avg_ppl / len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnyw4y0GJ2-O",
        "outputId": "b5afbc41-8389-4027-f7f4-dae660a1e067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89.18045429620587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SoJyaTDJ5-b",
        "outputId": "3e4ca0fc-79da-4c8d-ab24-0850406dd69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('caterpie metapod butterfree weedle kakuna beedrill paras parasect venonat venomoth scyther pinsir', 1.0) (\"`` crack '' cocaine\", 13670.813011882978)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(X_train, n=3)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "for sentence in X_test:\n",
        "    test_sent = list(ngrams(sentence, n=3))\n",
        "    value = perplexity(lm, test_sent, 3)\n",
        "    all_ppls.append((' '.join(sentence), value))\n",
        "    avg_ppl += value\n",
        "print(avg_ppl / len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzo8bc31K4jO",
        "outputId": "334283a5-0493-44d6-de66-46b60001870d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.931262401614887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OijT_tVHK5bu",
        "outputId": "0bcaec1b-750d-478c-ed99-9434b0fa2437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ayy , el mayo !', 1.0) ('so , so .....', 2349.4520992492407)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Использование готовых инструментов\n",
        "К счастью, нам всё писать необязательно. Необходимые функции и модули уже были написаны умными программистами. Давайте посмотрим на модуль nltk и на то, что он нам предлагает."
      ],
      "metadata": {
        "id": "x-qkSZRVK74I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "\n",
        "n = 1\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)"
      ],
      "metadata": {
        "id": "zZIp1wyA8is6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "X_test_list = X_test.tolist()\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    value = model.perplexity(test)\n",
        "    all_ppls.append((' '.join(X_test_list[i]), value))\n",
        "    if value != np.inf:\n",
        "        avg_ppl += value\n",
        "print(avg_ppl / i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEoczB6VPI6d",
        "outputId": "c8d02443-ab09-4b31-a4b1-4d5fabe5e18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1737.34229072188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте повторим то же самое но с моделями на биграммах и триграммах. Сравните результаты. Почему они такие?"
      ],
      "metadata": {
        "id": "BoIB9VzALHTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 2\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)\n",
        "\n",
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    value = model.perplexity(test)\n",
        "    all_ppls.append((' '.join(X_test_list[i]), value))\n",
        "    if value != np.inf:\n",
        "        avg_ppl += value\n",
        "print(avg_ppl / i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMMDDvD3OtOa",
        "outputId": "7393c110-ab19-434d-97de-d53aeb24e182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93.30178313379233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiHF-lBUOhxx",
        "outputId": "e5e6785f-0876-4a75-b6ef-a0a9d7e1791c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"i do n't .\", 31.782361206203593) (\"'doctor , i 'm starting to think that i may be a hypochrondriac . ' the doctor let him know that this was okay .\", inf)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, X_train)\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_vocab)\n",
        "\n",
        "test_data, _ = padded_everygram_pipeline(n, X_test)\n",
        "all_ppls = []\n",
        "avg_ppl = 0\n",
        "length = 0\n",
        "for i, test in enumerate(test_data):\n",
        "    value = model.perplexity(test)\n",
        "    all_ppls.append((' '.join(X_test_list[i]), value))\n",
        "    if value != np.inf:\n",
        "        avg_ppl += value\n",
        "print(avg_ppl / i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LJIJQfsP51f",
        "outputId": "8316f95c-0ffa-43cd-fe34-4948cc0114de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.886113628097343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = sorted(all_ppls, key=lambda x: x[1])\n",
        "print(s[0], s[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diq4c65qJpav",
        "outputId": "33e8afb3-0ed0-435d-ed37-2531e0800088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"i do n't .\", 14.247032242849127) (\"'doctor , i 'm starting to think that i may be a hypochrondriac . ' the doctor let him know that this was okay .\", inf)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "И давайте напоследок попробуем сгенерировать последовательность с помощью обученной модели:"
      ],
      "metadata": {
        "id": "fNYexOFULKq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(20, text_seed=['he'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_12r9gFqOhGu",
        "outputId": "a03897c8-b234-4bc1-ad4f-0d298afd3fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['asks',\n",
              " 'his',\n",
              " 'granfather',\n",
              " 'for',\n",
              " 'advice',\n",
              " '.',\n",
              " 'sincerely',\n",
              " ',',\n",
              " '&',\n",
              " 'amp',\n",
              " ';',\n",
              " 'it',\n",
              " 'was',\n",
              " 'a',\n",
              " 'free',\n",
              " 'bed',\n",
              " ',',\n",
              " \"''\",\n",
              " 'said',\n",
              " 'paddy']"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQFcyvlthGke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
