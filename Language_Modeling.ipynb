{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Генерация текста: н-граммы\n",
        "\n",
        "В этой тетрадке мы научимся делать простую модель генерации текста на основе н-грамм и встречаемости в корпусе."
      ],
      "metadata": {
        "id": "_pjlNnOv4Ut4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nlpXQYlpuwmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "TcWFfFlLgb1r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем пробовать генерировать шутки. Для обучения будем использовать [датасет с постами reddit](https://kaggle.com/datasets/thedevastator/one-million-reddit-jokes)."
      ],
      "metadata": {
        "id": "1WT4GhNjvba0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = # YOUR_PATH\n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "2VJz6GMP1nNu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "xDqSNS4s_tXc",
        "outputId": "1362b98b-d367-4956-ce75-8366a48e3bcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type      id subreddit.id subreddit.name  subreddit.nsfw  created_utc  \\\n",
              "0  post  ftbp1i        2qh72          jokes           False   1585785543   \n",
              "1  post  ftboup        2qh72          jokes           False   1585785522   \n",
              "2  post  ftbopj        2qh72          jokes           False   1585785508   \n",
              "3  post  ftbnxh        2qh72          jokes           False   1585785428   \n",
              "4  post  ftbjpg        2qh72          jokes           False   1585785009   \n",
              "\n",
              "                                           permalink      domain  url  \\\n",
              "0  https://old.reddit.com/r/Jokes/comments/ftbp1i...  self.jokes  NaN   \n",
              "1  https://old.reddit.com/r/Jokes/comments/ftboup...  self.jokes  NaN   \n",
              "2  https://old.reddit.com/r/Jokes/comments/ftbopj...  self.jokes  NaN   \n",
              "3  https://old.reddit.com/r/Jokes/comments/ftbnxh...  self.jokes  NaN   \n",
              "4  https://old.reddit.com/r/Jokes/comments/ftbjpg...  self.jokes  NaN   \n",
              "\n",
              "                                            selftext  \\\n",
              "0  My corona is covered with foreskin so it is no...   \n",
              "1                         It's called Google Sheets.   \n",
              "2  The vacuum doesn't snore after sex.\\r\\n\\r\\n&am...   \n",
              "3                                          [removed]   \n",
              "4                                          [removed]   \n",
              "\n",
              "                                               title  score  \n",
              "0               I am soooo glad I'm not circumcised!      2  \n",
              "1  Did you know Google now has a platform for rec...      9  \n",
              "2  What is the difference between my wife and my ...     15  \n",
              "3                              My last joke for now.      9  \n",
              "4              The Nintendo 64 turns 18 this week...    134  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0f0dfbfe-f396-4976-ad13-37e62abf9638\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit.id</th>\n",
              "      <th>subreddit.name</th>\n",
              "      <th>subreddit.nsfw</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>permalink</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>selftext</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbp1i</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785543</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbp1i...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My corona is covered with foreskin so it is no...</td>\n",
              "      <td>I am soooo glad I'm not circumcised!</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>post</td>\n",
              "      <td>ftboup</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785522</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftboup...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It's called Google Sheets.</td>\n",
              "      <td>Did you know Google now has a platform for rec...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbopj</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785508</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbopj...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The vacuum doesn't snore after sex.\\r\\n\\r\\n&amp;am...</td>\n",
              "      <td>What is the difference between my wife and my ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbnxh</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785428</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbnxh...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>My last joke for now.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbjpg</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785009</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbjpg...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>The Nintendo 64 turns 18 this week...</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f0dfbfe-f396-4976-ad13-37e62abf9638')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b57e4ca1-00f9-40be-9891-7367d12a3cbe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b57e4ca1-00f9-40be-9891-7367d12a3cbe')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b57e4ca1-00f9-40be-9891-7367d12a3cbe button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f0dfbfe-f396-4976-ad13-37e62abf9638 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f0dfbfe-f396-4976-ad13-37e62abf9638');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как наша задача генерации требует только текста, оставим только некоторые столбцы."
      ],
      "metadata": {
        "id": "QSHwGZ-S3t-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['selftext']\n",
        "data = data[columns]"
      ],
      "metadata": {
        "id": "Sg3r3lQI16CR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка данных\n",
        "###1. Чистка датасета\n",
        "\n",
        "__Подсказка:__ Часто пропуски они обозначаются как nan, но иногда можно заметить иные способы."
      ],
      "metadata": {
        "id": "edTMfW2Z6lBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR CODE HERE> #"
      ],
      "metadata": {
        "id": "8pI_AuFN6jqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Надо тексты привести к нижнему регистру. Пунктуацию можно оставить, так как она влияет на смысл предложения и на встречаемость.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы."
      ],
      "metadata": {
        "id": "dQ3V-peRAg3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import re"
      ],
      "metadata": {
        "id": "ZMjEpki3VmC5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text: str) -> list:\n",
        "     '''\n",
        "     Делит текст на слова и пунктуацию и приводит все к нижнему регистру\n",
        "     :param text: строка\n",
        "     :returns: список слов и знаков препинания\n",
        "     '''\n",
        "     # <YOUR CODE HERE> #\n",
        "     return"
      ],
      "metadata": {
        "id": "DbSc8NqvUq-t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['words'] = data['selftext'].apply(clean_text)\n",
        "data['lens'] = data['words'].apply(len)\n",
        "data = data[data.lens > 3]"
      ],
      "metadata": {
        "id": "ckQKt8tI_prG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = data['words'].tolist()"
      ],
      "metadata": {
        "id": "3htMqxgaCLmZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAjsJvvwT_t1",
        "outputId": "7131f4a2-8e2e-41b4-bd02-167744db3147"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['my',\n",
              "  'corona',\n",
              "  'is',\n",
              "  'covered',\n",
              "  'with',\n",
              "  'foreskin',\n",
              "  'so',\n",
              "  'it',\n",
              "  'is',\n",
              "  'not',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'viruses',\n",
              "  '.'],\n",
              " [\"it's\", 'called', 'google', 'sheets', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams\n",
        "Для начала попробуем создать самую простую модель, основанную на встречаемости н-граммы в корпусе."
      ],
      "metadata": {
        "id": "MUp_9FzUW3Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "mP00Mb3MlMeL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS = '[bos]', '[eos]'\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, lines, n):\n",
        "        assert n >= 1\n",
        "        self.n = n\n",
        "        counts = self.ngram_counts(lines, self.n)\n",
        "\n",
        "        # перевести количества в вероятности\n",
        "        self.probs = defaultdict(Counter)\n",
        "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
        "        # <YOUR CODE HERE> #\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        \"\"\"\n",
        "        :param prefix: строка запроса\n",
        "        :returns: словарь с возможными продолжениями заданного префикса\n",
        "        \"\"\"\n",
        "        prefix = prefix.split()\n",
        "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
        "        prefix = [ BOS ] * (self.n - 1 - len(prefix)) + prefix\n",
        "        return self.probs[tuple(prefix)]\n",
        "\n",
        "    @staticmethod\n",
        "    def ngram_counts(lines: list, n: int) -> dict:\n",
        "        '''\n",
        "        Создаёт словарь, где каждому префиксу (n-1 слово) присваивается словарь,\n",
        "        в котором ключи - слова, а значения - количество н-грамм в текстах\n",
        "        :param lines: список списков\n",
        "        :param n: количество слов в н-грамме\n",
        "        :returns: словарь, в котором для каждого в префикса известно количество\n",
        "        н-грамм с каждым словом\n",
        "        '''\n",
        "        dictionary = defaultdict(Counter)\n",
        "        # dictionary[(word1, word2)][word3] = count((word1, word2, word3))\n",
        "        # <YOUR CODE HERE> #\n",
        "        return dictionary\n",
        "\n",
        "# Проверим работу функции ngram_counts\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = NGramLanguageModel.ngram_counts(dummy_lines, n=3)\n",
        "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "assert len(dummy_counts[(BOS, BOS)]) == 66\n",
        "assert dummy_counts[BOS, 'a']['melon'] == 1\n",
        "\n",
        "# Проверим работу модели\n",
        "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
        "p_initial = dummy_lm.get_possible_next_tokens('')\n",
        "assert p_initial.most_common(1)[0][0] == 'a'"
      ],
      "metadata": {
        "id": "EQQpVdxSBahu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Попробуем составить предложение используя жадный метод."
      ],
      "metadata": {
        "id": "v96is9vGawaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm: NGramLanguageModel, prefix: str) -> str:\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    # <YOUR CODE HERE> #\n",
        "    return # next word"
      ],
      "metadata": {
        "id": "5p4C8r0TP-jj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "YcIeQluWfJ-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, prefix)\n",
        "while word != EOS:\n",
        "    prefix += f' {word}'\n",
        "    word = get_next_word(lm, prefix)\n",
        "\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "id": "rh9oYWyosfnG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Выбор наиболее вероятного слова не показал хороших результатов. Давайте попробуем семплировать методом top-k: выбираем k наиболее встречаемых вариантов и из них выбираем один случайным образом."
      ],
      "metadata": {
        "id": "euWO6e9hTRkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm: NGramLanguageModel, prefix: str, k:int) -> str:\n",
        "    '''\n",
        "    :param lm: language model\n",
        "    :param prefix: строка префикса\n",
        "    :param k: количество слов в top-k\n",
        "    :returns: следующее, наиболее вероятное, слово для данного префикса\n",
        "    '''\n",
        "    # <YOUR CODE HERE> #\n",
        "    return # next word"
      ],
      "metadata": {
        "id": "YlQNWIZrS-aK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for i in range(repeat):\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "gUlsfNObToqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, '', 5)\n",
        "while word != EOS:\n",
        "    prefix += f'{word} '\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "id": "nkBhxv88Ts0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Для сравнения можно сделать beam search. Напоминаем, что он на каждом шаге выбирает k наилучших вариантов - те, с которыми наибольшая вероятность всего предложения. Кроме этого надо не забыть, что мы переводим вероятности в логарифмы: таким образом считается сумма логарифмов вероятностей для каждой н-граммы, из которого состоит предложение.\n",
        "Чтобы не пересчитывать каждый раз корпус, давайте будем считать вероятность последней н-граммы.\n",
        "\n",
        "Попробуйте написать свой beam search, для n-gramm, где n=3 и для k=2."
      ],
      "metadata": {
        "id": "HC5axKpqtcvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "        \\frac{1}{L^\\alpha}\\sum_{t'=1}^LlogP(y^{t'}|y_{t'-n}, ..., y_{t'}, <bos>)\n",
        "    \\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "E3ceW1U7GPlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'he' # YOUR IDEA\n",
        "prefixes = [prefix, prefix]\n",
        "probs = [0, 0]\n",
        "k = 2\n",
        "\n",
        "# <YOUR CODE HERE> #"
      ],
      "metadata": {
        "id": "SetLttedXIKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {
        "id": "zCm30Mgf56Cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Решение"
      ],
      "metadata": {
        "id": "u3FtFBmg58KP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка данных\n",
        "###1. Чистка датасета\n",
        "\n",
        "Для начала надо избавиться от пустых строк, или же нанов. Часто они обозначаются как nan, но иногда можно заметить иные способы."
      ],
      "metadata": {
        "id": "qT2oie9T53nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['selftext'].value_counts()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdd2bd4-d67b-4631-b79a-e024655fd728",
        "id": "1BjPfU-S53nO"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[removed]                          232919\n",
              "[deleted]                          188442\n",
              "\\[removed\\]                           272\n",
              "To get to the other side.             125\n",
              "Dr. Dre                               111\n",
              "A stick.                               83\n",
              "None.                                  81\n",
              "A stick                                76\n",
              "He worked it out with a pencil.        74\n",
              "Then it hit me.                        72\n",
              "Name: selftext, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно заметить, что наиболее частым классом являются _removed_ или _deleted_."
      ],
      "metadata": {
        "id": "ldpt6ruF53nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Размер данных до чистки', data.shape)\n",
        "data = data[~data.isin(['[removed]', '[deleted]', '\\[removed\\]', 'removed', 'deleted'])]\n",
        "data = data.dropna()\n",
        "print('Размер данных после чистки', data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe828c5-fad1-43fd-e4c3-3d83f1c81708",
        "id": "DR50a_Lq53nO"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер данных до чистки (999998, 1)\n",
            "Размер данных после чистки (573887, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Надо тексты привести к нижнему регистру и убрать пунктуацию.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы."
      ],
      "metadata": {
        "id": "xI6azkP553nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import re"
      ],
      "metadata": {
        "id": "C55KqII853nP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "     text = text.lower()\n",
        "     new_text = []\n",
        "     for word in text.split():\n",
        "        if word.endswith(tuple(punctuation)):\n",
        "            new_text.append(word[:-1])\n",
        "            new_text.append(word[-1])\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "     return new_text"
      ],
      "metadata": {
        "id": "a7huFnfq53nP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['words'] = data['selftext'].apply(clean_text)\n",
        "data['lens'] = data['words'].apply(len)\n",
        "data = data[data.lens > 3]"
      ],
      "metadata": {
        "id": "-l96PkDv53nP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = data['words'].tolist()"
      ],
      "metadata": {
        "id": "MKbpYrvJ53nP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895f345d-ce53-4450-dd93-b9faeadadeb2",
        "id": "CKmViv5G53nP"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['my',\n",
              "  'corona',\n",
              "  'is',\n",
              "  'covered',\n",
              "  'with',\n",
              "  'foreskin',\n",
              "  'so',\n",
              "  'it',\n",
              "  'is',\n",
              "  'not',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'viruses',\n",
              "  '.'],\n",
              " [\"it's\", 'called', 'google', 'sheets', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams\n",
        "Для начала попробуем создать самую простую модель, основанную на встречаемости н-граммы в корпусе."
      ],
      "metadata": {
        "id": "wLqrE_jq53nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "BjxFUMET53nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS, UNK = '[bos]', '[eos]', '[unk]'\n",
        "\n",
        "def ngram_counts(lines, n):\n",
        "    dictionary = defaultdict(Counter)\n",
        "    for line in lines:\n",
        "        new_line = [BOS] * (n-1) + line + [EOS]\n",
        "        for i in range(n-1, len(new_line)):\n",
        "            prefix = tuple(new_line[i-n+1:i])\n",
        "            word = new_line[i]\n",
        "            dictionary[prefix][word] += 1\n",
        "    return dictionary\n",
        "\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = ngram_counts(dummy_lines, n=3)\n",
        "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "assert len(dummy_counts[(BOS, BOS)]) == 66\n",
        "assert dummy_counts[BOS, 'a']['melon'] == 1"
      ],
      "metadata": {
        "id": "d0Vikdb153nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS = '[bos]', '[eos]'\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, lines, n):\n",
        "        assert n >= 1\n",
        "        self.n = n\n",
        "        counts = self.ngram_counts(lines, self.n)\n",
        "\n",
        "        # перевести количества в вероятности\n",
        "        self.probs = defaultdict(Counter)\n",
        "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
        "\n",
        "        for key, value in counts.items():\n",
        "            sum_of_prefix = sum(value.values())\n",
        "            for word, cnts in value.items():\n",
        "                self.probs[key][word] = cnts / sum_of_prefix\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        \"\"\"\n",
        "        :param prefix: строка запроса\n",
        "        :returns: словарь с возможными продолжениями заданного префикса\n",
        "        \"\"\"\n",
        "        prefix = prefix.split()\n",
        "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
        "        prefix = [ BOS ] * (self.n - 1 - len(prefix)) + prefix\n",
        "        return self.probs[tuple(prefix)]\n",
        "\n",
        "    @staticmethod\n",
        "    def ngram_counts(lines, n):\n",
        "        dictionary = defaultdict(Counter)\n",
        "        for line in lines:\n",
        "            new_line = [BOS] * (n-1) + line + [EOS]\n",
        "            for i in range(n-1, len(new_line)):\n",
        "                prefix = tuple(new_line[i-n+1:i])\n",
        "                word = new_line[i]\n",
        "                dictionary[prefix][word] += 1\n",
        "        return dictionary\n",
        "\n",
        "# Проверим работу функции ngram_counts\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = NGramLanguageModel.ngram_counts(dummy_lines, n=3)\n",
        "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "assert len(dummy_counts[(BOS, BOS)]) == 66\n",
        "assert dummy_counts[BOS, 'a']['melon'] == 1\n",
        "\n",
        "# Проверим работу модели\n",
        "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
        "p_initial = dummy_lm.get_possible_next_tokens('')\n",
        "assert p_initial.most_common(1)[0][0] == 'a'"
      ],
      "metadata": {
        "id": "2BhgtJdoNh2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Жадный метод."
      ],
      "metadata": {
        "id": "C7qBxszJ53nQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm, prefix):\n",
        "    return lm.get_possible_next_tokens(prefix).most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "M4qpcfyH53nQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "VTAtUgCjNwxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, prefix)\n",
        "while word != EOS:\n",
        "    prefix += f' {word}'\n",
        "    word = get_next_word(lm, prefix)\n",
        "\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "id": "49u7GApNNwxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Top-k."
      ],
      "metadata": {
        "id": "fL_93t6753nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm, prefix, k):\n",
        "    next_words = lm.get_possible_next_tokens(prefix).most_common(k)\n",
        "    index = random.randint(0, min(k, len(next_words))-1)\n",
        "    return next_words[index][0]"
      ],
      "metadata": {
        "id": "acwYCEJe53nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "repeat = 20\n",
        "for _ in range(repeat):\n",
        "    word = get_next_word(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS):\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "id": "wI2ODnJCN1SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, prefix)\n",
        "while word != EOS:\n",
        "    prefix += f' {word}'\n",
        "    word = get_next_word(lm, prefix)\n",
        "\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "id": "o-rWLLT6N1SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Beam search"
      ],
      "metadata": {
        "id": "fOgqjZl653nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'he' # YOUR IDEA\n",
        "prefixes = [prefix, prefix]\n",
        "probs = [0, 0]\n",
        "k = 2\n",
        "\n",
        "step = 1\n",
        "while (not prefixes[0].endswith(EOS)) and (not prefixes[1].endswith(EOS)) and (step != 20):\n",
        "    print('step', step)\n",
        "    print(prefixes, probs, sep='\\n')\n",
        "    step += 1\n",
        "    possible_words1 = lm.get_possible_next_tokens(prefixes[0]).most_common(k)\n",
        "    probs1 = []\n",
        "    for word in possible_words1:\n",
        "        probs1.append((word[0], 1/(step)*(probs[0]+np.log(word[1])), probs[0]+np.log(word[1])))\n",
        "    possible_words2 = lm.get_possible_next_tokens(prefixes[1]).most_common(k)\n",
        "    probs2 = []\n",
        "    for word in possible_words2:\n",
        "        probs2.append((word[0], 1/(step)*(probs[1]+np.log(word[1])), probs[0]+np.log(word[1])))\n",
        "    choice = []\n",
        "    probs1 = sorted(probs1, key=lambda x: x[1], reverse=True)\n",
        "    probs2 = sorted(probs2, key=lambda x: x[1], reverse=True)\n",
        "    probs_new = []\n",
        "    while len(choice) != k and len(probs1) != 0 and len(probs2) != 0:\n",
        "        if probs1[0][1] > probs2[0][1]:\n",
        "            choice.append(prefixes[0] + f' {probs1[0][0]}')\n",
        "            probs_new.append(probs1[0][2])\n",
        "            probs1 = probs1[1:]\n",
        "            possible_words1 = probs1[1:]\n",
        "        else:\n",
        "            choice.append(prefixes[1] + f' {probs2[0][0]}')\n",
        "            probs_new.append(probs2[0][2])\n",
        "            probs2 = probs2[1:]\n",
        "            possible_words2 = probs2[1:]\n",
        "    prefixes = choice\n",
        "    probs = probs_new"
      ],
      "metadata": {
        "id": "lMpqMOsk53nS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}