{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nlpXQYlpuwmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "TcWFfFlLgb1r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем пробовать генерировать шутки. Для обучения будем использовать [датасет с постами reddit](https://kaggle.com/datasets/thedevastator/one-million-reddit-jokes)."
      ],
      "metadata": {
        "id": "1WT4GhNjvba0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/NLP_manual/Datasets/reddit_jokes.csv'\n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "2VJz6GMP1nNu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "xDqSNS4s_tXc",
        "outputId": "1362b98b-d367-4956-ce75-8366a48e3bcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type      id subreddit.id subreddit.name  subreddit.nsfw  created_utc  \\\n",
              "0  post  ftbp1i        2qh72          jokes           False   1585785543   \n",
              "1  post  ftboup        2qh72          jokes           False   1585785522   \n",
              "2  post  ftbopj        2qh72          jokes           False   1585785508   \n",
              "3  post  ftbnxh        2qh72          jokes           False   1585785428   \n",
              "4  post  ftbjpg        2qh72          jokes           False   1585785009   \n",
              "\n",
              "                                           permalink      domain  url  \\\n",
              "0  https://old.reddit.com/r/Jokes/comments/ftbp1i...  self.jokes  NaN   \n",
              "1  https://old.reddit.com/r/Jokes/comments/ftboup...  self.jokes  NaN   \n",
              "2  https://old.reddit.com/r/Jokes/comments/ftbopj...  self.jokes  NaN   \n",
              "3  https://old.reddit.com/r/Jokes/comments/ftbnxh...  self.jokes  NaN   \n",
              "4  https://old.reddit.com/r/Jokes/comments/ftbjpg...  self.jokes  NaN   \n",
              "\n",
              "                                            selftext  \\\n",
              "0  My corona is covered with foreskin so it is no...   \n",
              "1                         It's called Google Sheets.   \n",
              "2  The vacuum doesn't snore after sex.\\r\\n\\r\\n&am...   \n",
              "3                                          [removed]   \n",
              "4                                          [removed]   \n",
              "\n",
              "                                               title  score  \n",
              "0               I am soooo glad I'm not circumcised!      2  \n",
              "1  Did you know Google now has a platform for rec...      9  \n",
              "2  What is the difference between my wife and my ...     15  \n",
              "3                              My last joke for now.      9  \n",
              "4              The Nintendo 64 turns 18 this week...    134  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0f0dfbfe-f396-4976-ad13-37e62abf9638\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit.id</th>\n",
              "      <th>subreddit.name</th>\n",
              "      <th>subreddit.nsfw</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>permalink</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>selftext</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbp1i</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785543</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbp1i...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My corona is covered with foreskin so it is no...</td>\n",
              "      <td>I am soooo glad I'm not circumcised!</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>post</td>\n",
              "      <td>ftboup</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785522</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftboup...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It's called Google Sheets.</td>\n",
              "      <td>Did you know Google now has a platform for rec...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbopj</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785508</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbopj...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The vacuum doesn't snore after sex.\\r\\n\\r\\n&amp;am...</td>\n",
              "      <td>What is the difference between my wife and my ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbnxh</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785428</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbnxh...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>My last joke for now.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>post</td>\n",
              "      <td>ftbjpg</td>\n",
              "      <td>2qh72</td>\n",
              "      <td>jokes</td>\n",
              "      <td>False</td>\n",
              "      <td>1585785009</td>\n",
              "      <td>https://old.reddit.com/r/Jokes/comments/ftbjpg...</td>\n",
              "      <td>self.jokes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>The Nintendo 64 turns 18 this week...</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f0dfbfe-f396-4976-ad13-37e62abf9638')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b57e4ca1-00f9-40be-9891-7367d12a3cbe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b57e4ca1-00f9-40be-9891-7367d12a3cbe')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b57e4ca1-00f9-40be-9891-7367d12a3cbe button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f0dfbfe-f396-4976-ad13-37e62abf9638 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f0dfbfe-f396-4976-ad13-37e62abf9638');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как наша задача генерации требует только текста, оставим только некоторые столбцы."
      ],
      "metadata": {
        "id": "QSHwGZ-S3t-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['selftext']\n",
        "data = data[columns]"
      ],
      "metadata": {
        "id": "Sg3r3lQI16CR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка данных\n",
        "###1. Чистка датасета\n",
        "\n",
        "Для начала надо избавиться от пустых строк, или же нанов. Часто они обозначаются как nan, но иногда можно заметить иные способы."
      ],
      "metadata": {
        "id": "edTMfW2Z6lBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['selftext'].value_counts()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvFzrnqH3qjG",
        "outputId": "de19ea82-9fb1-450b-d771-94e2b88f5322"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[removed]                          232919\n",
              "[deleted]                          188442\n",
              "\\[removed\\]                           272\n",
              "To get to the other side.             125\n",
              "Dr. Dre                               111\n",
              "A stick.                               83\n",
              "None.                                  81\n",
              "A stick                                76\n",
              "He worked it out with a pencil.        74\n",
              "Then it hit me.                        72\n",
              "Name: selftext, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно заметить, что наиболее частым классом являются _removed_ или _deleted_."
      ],
      "metadata": {
        "id": "0BcsjwYx79Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Размер данных до чистки', data.shape)\n",
        "data = data[~data.isin(['[removed]', '[deleted]', '\\[removed\\]', 'removed', 'deleted'])]\n",
        "data = data.dropna()\n",
        "print('Размер данных после чистки', data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pI_AuFN6jqJ",
        "outputId": "2bbfc04e-f9cd-41f6-bda0-8fbd6610530d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер данных до чистки (999998, 1)\n",
            "Размер данных после чистки (573887, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Надо тексты привести к нижнему регистру и убрать пунктуацию.\n",
        "Кроме этого можно избавиться от совсем коротких шуток, так как скорее всего это просто ответы на фразы."
      ],
      "metadata": {
        "id": "dQ3V-peRAg3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import re"
      ],
      "metadata": {
        "id": "ZMjEpki3VmC5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "     text = text.lower()\n",
        "     #text = re.sub(r'[^\\w\\s\\.]', '', text)\n",
        "     new_text = []\n",
        "     for word in text.split():\n",
        "        if word.endswith(tuple(punctuation)):\n",
        "            new_text.append(word[:-1])\n",
        "            new_text.append(word[-1])\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "     return new_text"
      ],
      "metadata": {
        "id": "DbSc8NqvUq-t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['words'] = data['selftext'].apply(clean_text)\n",
        "#data['words'] = data['clean_text'].apply(str.split)\n",
        "data['lens'] = data['words'].apply(len)\n",
        "data = data[data.lens > 3]"
      ],
      "metadata": {
        "id": "ckQKt8tI_prG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Обработка текста"
      ],
      "metadata": {
        "id": "Uk-rwbJwDT8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = data['words'].tolist()"
      ],
      "metadata": {
        "id": "3htMqxgaCLmZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAjsJvvwT_t1",
        "outputId": "7131f4a2-8e2e-41b4-bd02-167744db3147"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['my',\n",
              "  'corona',\n",
              "  'is',\n",
              "  'covered',\n",
              "  'with',\n",
              "  'foreskin',\n",
              "  'so',\n",
              "  'it',\n",
              "  'is',\n",
              "  'not',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'viruses',\n",
              "  '.'],\n",
              " [\"it's\", 'called', 'google', 'sheets', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams\n",
        "Для начала попробуем создать самую простую модель, основанную на встречаемости н-граммы в корпусе."
      ],
      "metadata": {
        "id": "MUp_9FzUW3Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "mP00Mb3MlMeL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем токены начала и конца\n",
        "BOS, EOS, UNK = '[bos]', '[eos]', '[unk]'\n",
        "\n",
        "def ngram_counts(lines, n):\n",
        "    dictionary = defaultdict(Counter)\n",
        "    for line in lines:\n",
        "        new_line = [BOS] * (n-1) + line + [EOS]\n",
        "        for i in range(n-1, len(new_line)):\n",
        "            prefix = tuple(new_line[i-n+1:i])\n",
        "            word = new_line[i]\n",
        "            dictionary[prefix][word] += 1\n",
        "    return dictionary\n",
        "\n",
        "dummy_lines = sorted(words, key=len)[:100]\n",
        "dummy_counts = ngram_counts(dummy_lines, n=3)\n",
        "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
        "assert len(dummy_counts[(BOS, BOS)]) == 66\n",
        "assert dummy_counts[BOS, 'a']['melon'] == 1"
      ],
      "metadata": {
        "id": "U4XrsvFdUAtW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NGramLanguageModel:\n",
        "    def __init__(self, lines, n):\n",
        "        assert n >= 1\n",
        "        self.n = n\n",
        "\n",
        "        counts = self.ngram_counts(lines, self.n)\n",
        "\n",
        "        # compute token proabilities given counts\n",
        "        self.probs = defaultdict(Counter)\n",
        "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
        "\n",
        "        # populate self.probs with actual probabilities\n",
        "        for key, value in counts.items():\n",
        "            sum_of_prefix = sum(value.values())\n",
        "            for word, cnts in value.items():\n",
        "                self.probs[key][word] = cnts / sum_of_prefix\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        \"\"\"\n",
        "        :param prefix: string with space-separated prefix tokens\n",
        "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
        "        \"\"\"\n",
        "        prefix = prefix.split()\n",
        "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
        "        prefix = [ BOS ] * (self.n - 1 - len(prefix)) + prefix\n",
        "        return self.probs[tuple(prefix)]\n",
        "\n",
        "    def get_next_token_prob(self, prefix, next_token):\n",
        "        \"\"\"\n",
        "        :param prefix: string with space-separated prefix tokens\n",
        "        :param next_token: the next token to predict probability for\n",
        "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
        "        \"\"\"\n",
        "        return self.get_possible_next_tokens(prefix).get(next_token, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def ngram_counts(lines, n):\n",
        "        dictionary = defaultdict(Counter)\n",
        "        for line in lines:\n",
        "            new_line = [BOS] * (n-1) + line + [EOS]\n",
        "            for i in range(n-1, len(new_line)):\n",
        "                prefix = tuple(new_line[i-n+1:i])\n",
        "                word = new_line[i]\n",
        "                dictionary[prefix][word] += 1\n",
        "        return dictionary"
      ],
      "metadata": {
        "id": "TcjV1-_iqSnL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
        "p_initial = dummy_lm.get_possible_next_tokens('')\n",
        "assert p_initial.most_common(1)[0][0] == 'a'"
      ],
      "metadata": {
        "id": "b_CojFsNrd8D"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Попробуем составить предложение используя жадный метод."
      ],
      "metadata": {
        "id": "v96is9vGawaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm, prefix):\n",
        "    return lm.get_possible_next_tokens(prefix).most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "5p4C8r0TP-jj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)\n",
        "prefix = 'get'\n",
        "for i in range(100):\n",
        "    word = get_next_word(lm, prefix)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcIeQluWfJ-f",
        "outputId": "5013daf8-d7fe-401c-8a96-8d653388f606"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get off the roof . [eos]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ''\n",
        "word = lm.get_possible_next_tokens('').most_common(1)[0][0]\n",
        "while word != EOS:\n",
        "    sentence += f' {word}'\n",
        "    word = lm.get_possible_next_tokens(sentence).most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "rh9oYWyosfnG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "id": "t9PEbrKHsnoB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "553d1299-4c93-4b6a-af45-76d9f4bab7b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' i was a little bit of a sudden , the man says , \"i don\\'t know what to do with the same thing .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Выбор наиболее вероятного слова не показал хороших результатов. Давайте попробуем семплировать методом top-k."
      ],
      "metadata": {
        "id": "euWO6e9hTRkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_word(lm, prefix, k):\n",
        "    next_words = lm.get_possible_next_tokens(prefix).most_common(k)\n",
        "    index = random.randint(0, min(k, len(next_words))-1)\n",
        "    return next_words[index][0]"
      ],
      "metadata": {
        "id": "YlQNWIZrS-aK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NGramLanguageModel(words, n=3)"
      ],
      "metadata": {
        "id": "qA4nmRPcYAH6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = 'get'\n",
        "for i in range(100):\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "    prefix += ' ' + word\n",
        "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
        "        break\n",
        "\n",
        "print(prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUlsfNObToqk",
        "outputId": "b8528b8b-f079-4fe1-8985-9ae9367712e3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get a better look and says \"i never knew you were a couple of weeks . after a long day at noon . so the man says \"i want my left breast . but i was going fishing on his way . some years later . so the guy is sitting on top and said : \"you are on me ! my favorite joke ) edit 4 : went bankrupt before i could see it . the second nun , who is in the back room to check it out. ' the woman says : i know you could get rid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = ''\n",
        "word = get_next_word(lm, '', 5)\n",
        "while word != EOS:\n",
        "    prefix += f'{word} '\n",
        "    word = get_next_word(lm, prefix, 5)\n",
        "print(prefix + f'{word} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkBhxv88Ts0_",
        "outputId": "13d32d72-5c6c-46f9-f70c-cd9215839072"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "because it would take me out of it ! i don't like to hear a zipper on his head . so i asked my mom was a very attractive , older men were in the world , an elderly man in line to get a drink . as he can see your license , that would have been the same question : what ? [eos] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Для сравнения можно сделать beam search. Напоминаем, что он на каждом шаге выбирает k наилучших вариантов - те, с которыми наибольшая вероятность всего предложения."
      ],
      "metadata": {
        "id": "HC5axKpqtcvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = 'he'\n",
        "#lm = NGramLanguageModel(words, n=3)\n",
        "#next_word = lm.get_possible_next_tokens(prefix).most_common(1)[0]\n",
        "#prefix += next_word[0]\n",
        "#prob = next_word[1]\n",
        "prob=1\n",
        "\n",
        "k = 5\n",
        "best_k = 2\n",
        "next_word = lm.get_possible_next_tokens(prefix).most_common(best_k)\n",
        "prefixes = [prefix + f' {next_word[0][0]}', prefix + f' {next_word[1][0]}']\n",
        "probs = [prob * next_word[0][1], prob * next_word[1][1]]\n",
        "\n",
        "#for step in range(5):\n",
        "step = 1\n",
        "while (not prefixes[0].endswith(EOS)) and (not prefixes[0].endswith(EOS)) and (step != 20):\n",
        "    print('step', step)\n",
        "    step += 1\n",
        "    print(prefixes, probs, sep='\\n')\n",
        "    possible_words1 = lm.get_possible_next_tokens(prefixes[0]).most_common(best_k)\n",
        "    probs1 = []\n",
        "    for word in possible_words1:\n",
        "        probs1.append((word[0], probs[0]*word[1]))\n",
        "    possible_words2 = lm.get_possible_next_tokens(prefixes[1]).most_common(best_k)\n",
        "    probs2 = []\n",
        "    for word in possible_words2:\n",
        "        probs2.append((word[0], probs[1]*word[1]))\n",
        "    choice = []\n",
        "    probs1 = sorted(probs1, key=lambda x: x[1], reverse=True)\n",
        "    probs2 = sorted(probs2, key=lambda x: x[1], reverse=True)\n",
        "    probs_new = []\n",
        "    while len(choice) != best_k and len(probs1) != 0 and len(probs2) != 0:\n",
        "        if probs1[0][1] > probs2[0][1]:\n",
        "            choice.append(prefixes[0] + f' {probs1[0][0]}')\n",
        "            probs_new.append(probs[0] * probs1[0][1])\n",
        "            probs1 = probs1[1:]\n",
        "            possible_words1 = probs1[1:]\n",
        "        else:\n",
        "            choice.append(prefixes[1] + f' {probs2[0][0]}')\n",
        "            probs_new.append(probs[1] * probs2[0][1])\n",
        "            probs2 = probs2[1:]\n",
        "            possible_words2 = probs2[1:]\n",
        "    prefixes = choice\n",
        "    probs = probs_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpPrAjLPT3Vt",
        "outputId": "12a4a2c6-9a18-4397-96c5-ff066e0fc3c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1\n",
            "['he was', 'he said']\n",
            "[0.1389352775854344, 0.07018044071524582]\n",
            "step 2\n",
            "['he said ,', 'he was a']\n",
            "[0.0016555081057632137, 0.001751799011952464]\n",
            "step 3\n",
            "['he said , \"i', 'he was a little']\n",
            "[2.0088509635331525e-07, 1.2258589536713203e-07]\n",
            "step 4\n",
            "['he said , \"i don\\'t', 'he said , \"i have']\n",
            "[4.097103808716215e-15, 2.373165769238488e-15]\n",
            "step 5\n",
            "['he said , \"i don\\'t know', 'he said , \"i have a']\n",
            "[6.217719161567378e-30, 1.4285188701674254e-30]\n",
            "step 6\n",
            "['he said , \"i don\\'t know what', 'he said , \"i don\\'t know ,']\n",
            "[7.020224514695353e-60, 6.707925370390092e-60]\n",
            "step 7\n",
            "['he said , \"i don\\'t know , i', 'he said , \"i don\\'t know what to']\n",
            "[8.326080119732219e-120, 6.431011625809181e-120]\n",
            "step 8\n",
            "['he said , \"i don\\'t know what to do', 'he said , \"i don\\'t know what to say']\n",
            "[2.5991189639290983e-239, 3.488291241062737e-240]\n",
            "step 9\n",
            "['he said , \"i don\\'t know what to do with', 'he said , \"i don\\'t know what to do it']\n",
            "[0.0, 0.0]\n",
            "step 10\n",
            "['he said , \"i don\\'t know what to do it .', 'he said , \"i don\\'t know what to do it ,']\n",
            "[0.0, 0.0]\n",
            "step 11\n",
            "['he said , \"i don\\'t know what to do it , and', 'he said , \"i don\\'t know what to do it , but']\n",
            "[0.0, 0.0]\n",
            "step 12\n",
            "['he said , \"i don\\'t know what to do it , but i', 'he said , \"i don\\'t know what to do it , but the']\n",
            "[0.0, 0.0]\n",
            "step 13\n",
            "['he said , \"i don\\'t know what to do it , but the man', 'he said , \"i don\\'t know what to do it , but the other']\n",
            "[0.0, 0.0]\n",
            "step 14\n",
            "['he said , \"i don\\'t know what to do it , but the other side', 'he said , \"i don\\'t know what to do it , but the other is']\n",
            "[0.0, 0.0]\n",
            "step 15\n",
            "['he said , \"i don\\'t know what to do it , but the other is a', 'he said , \"i don\\'t know what to do it , but the other is in']\n",
            "[0.0, 0.0]\n",
            "step 16\n",
            "['he said , \"i don\\'t know what to do it , but the other is in the', 'he said , \"i don\\'t know what to do it , but the other is in a']\n",
            "[0.0, 0.0]\n",
            "step 17\n",
            "['he said , \"i don\\'t know what to do it , but the other is in a bar', 'he said , \"i don\\'t know what to do it , but the other is in a few']\n",
            "[0.0, 0.0]\n",
            "step 18\n",
            "['he said , \"i don\\'t know what to do it , but the other is in a few minutes', 'he said , \"i don\\'t know what to do it , but the other is in a few days']\n",
            "[0.0, 0.0]\n",
            "step 19\n",
            "['he said , \"i don\\'t know what to do it , but the other is in a few days later', 'he said , \"i don\\'t know what to do it , but the other is in a few days ,']\n",
            "[0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = 'because'\n",
        "#lm = NGramLanguageModel(words, n=3)\n",
        "#next_word = lm.get_possible_next_tokens(prefix).most_common(1)[0]\n",
        "#prefix += next_word[0]\n",
        "#prob = next_word[1]\n",
        "prob=1\n",
        "\n",
        "k = 5\n",
        "best_k = 2\n",
        "next_word = lm.get_possible_next_tokens(prefix).most_common(best_k)\n",
        "prefixes = [prefix + f' {next_word[0][0]}', prefix + f' {next_word[1][0]}']\n",
        "probs = [prob * np.log(next_word[0][1]), prob * np.log(next_word[1][1])]\n",
        "\n",
        "#for step in range(5):\n",
        "step = 1\n",
        "while (not prefixes[0].endswith(EOS)) and (not prefixes[1].endswith(EOS)) and (step != 20):\n",
        "    print('step', step)\n",
        "    step += 1\n",
        "    print(prefixes, probs, sep='\\n')\n",
        "    possible_words1 = lm.get_possible_next_tokens(prefixes[0]).most_common(best_k)\n",
        "    probs1 = []\n",
        "    for word in possible_words1:\n",
        "        probs1.append((word[0], 1/(step+1)*(probs[0]+np.log(word[1]))))\n",
        "    possible_words2 = lm.get_possible_next_tokens(prefixes[1]).most_common(best_k)\n",
        "    probs2 = []\n",
        "    for word in possible_words2:\n",
        "        probs2.append((word[0], 1/(step+1)*(probs[1]+np.log(word[1]))))\n",
        "    choice = []\n",
        "    probs1 = sorted(probs1, key=lambda x: x[1], reverse=True)\n",
        "    probs2 = sorted(probs2, key=lambda x: x[1], reverse=True)\n",
        "    probs_new = []\n",
        "    while len(choice) != best_k and len(probs1) != 0 and len(probs2) != 0:\n",
        "        if probs1[0][1] > probs2[0][1]:\n",
        "            choice.append(prefixes[0] + f' {probs1[0][0]}')\n",
        "            probs_new.append(probs[0] * probs1[0][1])\n",
        "            probs1 = probs1[1:]\n",
        "            possible_words1 = probs1[1:]\n",
        "        else:\n",
        "            choice.append(prefixes[1] + f' {probs2[0][0]}')\n",
        "            probs_new.append(probs[1] * probs2[0][1])\n",
        "            probs2 = probs2[1:]\n",
        "            possible_words2 = probs2[1:]\n",
        "    prefixes = choice\n",
        "    probs = probs_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SetLttedXIKf",
        "outputId": "940e4ebf-79f4-4238-fcc9-f7451ea91a3f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1\n",
            "['because they', 'because he']\n",
            "[-1.810170175064868, -1.9319008203695496]\n",
            "step 2\n",
            "['because he was', 'because they are']\n",
            "[2.2086360066108317, 2.275294391976661]\n",
            "step 3\n",
            "['because he was a', 'because they are both']\n",
            "[-0.10545234172117024, -0.3833335623358987]\n",
            "step 4\n",
            "['because he was a little', 'because he was a bit']\n",
            "[0.07014019480820664, 0.08140607177199918]\n",
            "step 5\n",
            "['because he was a bit of', 'because he was a bit ,']\n",
            "[-0.02267668699102755, -0.030634148384618986]\n",
            "step 6\n",
            "['because he was a bit of a', 'because he was a bit , and']\n",
            "[0.003795426211422038, 0.006442133000250419]\n",
            "step 7\n",
            "['because he was a bit , and the', 'because he was a bit of a sudden']\n",
            "[-0.001882908284150799, -0.0011293985996205466]\n",
            "step 8\n",
            "['because he was a bit of a sudden ,', 'because he was a bit of a sudden the']\n",
            "[0.00014219202611013022, 0.0002849389368838768]\n",
            "step 9\n",
            "['because he was a bit of a sudden , the', 'because he was a bit of a sudden , a']\n",
            "[-2.0241599435691766e-05, -2.0241599435691766e-05]\n",
            "step 10\n",
            "['because he was a bit of a sudden , the man', 'because he was a bit of a sudden , a man']\n",
            "[4.785805029292365e-06, 6.215583017537315e-06]\n",
            "step 11\n",
            "['because he was a bit of a sudden , a man walks', 'because he was a bit of a sudden , the man says']\n",
            "[-1.2587051202357575e-06, -1.0555994779385485e-06]\n",
            "step 12\n",
            "['because he was a bit of a sudden , a man walks into', 'because he was a bit of a sudden , the man says ,']\n",
            "[6.742805736459727e-08, 7.861299155721469e-08]\n",
            "step 13\n",
            "['because he was a bit of a sudden , a man walks into a', 'because he was a bit of a sudden , a man walks into the']\n",
            "[-1.7932132378521968e-09, -7.286716125874366e-09]\n",
            "step 14\n",
            "['because he was a bit of a sudden , a man walks into a bar', 'because he was a bit of a sudden , a man walks into the bar']\n",
            "[1.5268013422436392e-10, 1.4324496362655209e-09]\n",
            "step 15\n",
            "['because he was a bit of a sudden , a man walks into a bar and', 'because he was a bit of a sudden , a man walks into a bar .']\n",
            "[-1.2448747795854793e-11, -1.306406299294401e-11]\n",
            "step 16\n",
            "['because he was a bit of a sudden , a man walks into a bar . the', 'because he was a bit of a sudden , a man walks into a bar and orders']\n",
            "[1.0609912681254292e-12, 1.4505299601411942e-12]\n",
            "step 17\n",
            "['because he was a bit of a sudden , a man walks into a bar and orders a', 'because he was a bit of a sudden , a man walks into a bar . the man']\n",
            "[-4.5182716795155605e-14, -1.485922784843789e-13]\n",
            "step 18\n",
            "['because he was a bit of a sudden , a man walks into a bar and orders a drink', 'because he was a bit of a sudden , a man walks into a bar and orders a beer']\n",
            "[3.307136244229665e-15, 3.663236422295734e-15]\n",
            "step 19\n",
            "['because he was a bit of a sudden , a man walks into a bar and orders a drink .', 'because he was a bit of a sudden , a man walks into a bar and orders a beer .']\n",
            "[-1.7172598440411998e-16, -2.1492646705831714e-16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DE8IFevcdMem"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}