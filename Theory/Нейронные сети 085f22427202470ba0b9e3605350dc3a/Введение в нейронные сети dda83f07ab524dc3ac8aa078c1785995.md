# Введение в нейронные сети

Языковые модели и наивные байесовские модели, которые мы успели рассмотреть, называются статистическими моделями, так как основаны на вероятностном распределении и статистических методах. Однако, данные часто устроены более сложным образом, поэтому в ход идут более сложные инструменты как модели машинного обучения. В главе про основы машинного обучения мы обсудили структуру работы над моделями: какие они бывают, какие задачи они решают и как обучаются. Теперь стоит понять, как и из чего они устроены.

# Основная идея

Мы уже говорили, что модель - это функция вида $y = f(x)$. В качестве $x$ **мы представляем некоторый вектор числовых признаков, которые умножаются на вектор весов такой же длины $w$ **и в результате получаем число $y$*.* Давайте попробуем на примере разобрать этот процесс. 

Пусть мы хотим предсказать стоимость конфет “Нейрон” по их характеристикам. Тогда мы решаем задачу регрессии и строим модель линейной регрессии. Признаками будут: *количество конфет в упаковке, наличие орехов в начинке, вес одной конфеты*. Если вектор весов будет состоять из единиц, то значит, что все признаки вносят одинаковый вклад в ответ.

![image_1.png](%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B2%20%D0%BD%D0%B5%D0%B8%CC%86%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%20dda83f07ab524dc3ac8aa078c1785995/image_1.png)

Но кажется, кто ореховая начинка может сильнее влиять на цену, чем, например, вес конфеты (например, ферерро роше все очень любят). С этим можно и поспорить, но для чистоты эксперимента в нашем примере скажем так: “Люди города Q очень любят ореховые конфеты, поэтому продавцы в городе часто завышают цены на них. В то время как вес конфет часто мало беспокоит как покупателей, так и продавцов”. Тогда делать вектор весов из единиц не имеет смысла. На основе наших выводов поменяем немного вектор весов:

![Снимок экрана 2023-11-26 в 22.30.56.png](%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B2%20%D0%BD%D0%B5%D0%B8%CC%86%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%20dda83f07ab524dc3ac8aa078c1785995/%25D0%25A1%25D0%25BD%25D0%25B8%25D0%25BC%25D0%25BE%25D0%25BA_%25D1%258D%25D0%25BA%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B0_2023-11-26_%25D0%25B2_22.30.56.png)

То есть вектор весов показывает, что наиболее важным признаком для определения стоимости становится “наличие орехов в начинке”, в то время как век одной конфеты влияет на стоимость меньше.

Таким образом, наша функция это:

$$
y = \sum_i^{N}w_i \cdot x + b
$$

Параметр $b$ - это свободный коэффициент, который двигает график функции вверх-вниз, то есть это некоторый член, который не относится ни к какому признаку, а одинаков для каждого из объектов.

Формула выше считает ответ отдельно для каждого объекта. Такой способ может быть долгим. На самом деле набор данных - это матрица объектов размера MxN, где M - количество объектов, а N - количество признаков. Тогда мы можем привести наши вычисления к матричным преобразованиям. Следовательно, вектор весов имеет размерность Nx1 - количество признаков с некоторыми весами сводятся к одному числу - ответу. Тогда мы можем представить функцию как:

$$
y = X_{MxN}\cdot w_{Nx1} + b_{Mx1}
$$

В этой формуле мы так же сталкиваемся со свободным коэффициентом, который имеет размерность Mx1, так как мы прибавляем его к каждому объекту в данных. Чтобы не делать отдельный вектор свободного коэффициента часто просто делают дополнительный константный признак для каждого объекта равный единице.

Однако такой подход позволяет моделировать только линейные функции, то есть функции, графиком которых является прямая.

![image_2.png](%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B2%20%D0%BD%D0%B5%D0%B8%CC%86%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%20dda83f07ab524dc3ac8aa078c1785995/image_2.png)

Но что если наши данные распределены нелинейно, например так:

![Снимок экрана 2023-11-26 в 22.43.39.png](%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B2%20%D0%BD%D0%B5%D0%B8%CC%86%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%20dda83f07ab524dc3ac8aa078c1785995/%25D0%25A1%25D0%25BD%25D0%25B8%25D0%25BC%25D0%25BE%25D0%25BA_%25D1%258D%25D0%25BA%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B0_2023-11-26_%25D0%25B2_22.43.39.png)

В таких случаях простые линейные модели не очень подойдут. Есть несколько способов справляться с такими данными:

1. Добавлять *полиномиальные признаки*, например, возводить какие-то признаки в степень, или считать корень/синус от признака. Такой метод позволит усилить влияние признака или приблизить распределение признака к линейному. Но основная проблема такого подхода заключается в том, что полиномиальные признаки нужно подбирать самим, а это не такая тривиальная задача. 
2. Использовать методы деревьев решений. В данном курсе мы их не рассматриваем, но если хочется о них узнать побольше, можно прочитать на [здесь](https://www.geeksforgeeks.org/decision-tree-introduction-example/) или [здесь](https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya).
3. Применять несколько функций, то есть вместо функции вида $y = f(x)$  сделать функцию вида $y = g(h(f(x)))$ или ещё глубже.

Последний третий метод мы и рассмотрим. Такой набор различных функций и называется **нейронной сетью**. Иногда также можно встретить термин **многослойный перцептрон (multi-layer perceptron, MLP)**

## Устройство нейронной сети

**Нейронная сеть** - это последовательность различных преобразований данных, на каждом этапе которых извлекаются признаки другого порядка. Другими словами, на каждом этапе преобразований объект новый изменённый вектор или же признаки более высокого порядка. Базовый слой нейронной сети - линейный слой, который похож на линейную регрессию. Обычно этот слой называется **полносвязным**.

Представим простую нейронную сеть, состоящую из двух полносвязных слоёв. В отличие от линейной регрессии выходом полносвязного слоя часто является не одно число, а вектор чисел. Тогда вместо вектора весов мы получаем матрицу весов размера N1xN2, где N1 - это количество признаков изначально, а N2 - количество признаков после применения функции. Раз у нас два полносвязных слоя, то у нас две матрицы весов: W1 размера N1xN2, W2 размера N2x1.  Для простоты написания опустим свободный член $b$, будем считать, что вместо этого в матрицу $X$ добавлен константный признак.

$$
y = (X_{M×N_1}\cdot W_{N_1×N_2})\cdot W_{N_2×1} = X_{M×N_1}\cdot W_{N_1×N_2}\cdot W_{N_2×1} = X_{M×N_1} \cdot W_{N_1×1}
$$

Как можно заметить по формуле выше, две матрицы весов подряд равны одной матрице весов. То есть два линейных преобразования идентичны обычному линейному преобразованию, то есть линейной регрессии. Следовательно, чтобы можно было добавлять несколько линейных слоёв, надо добавить нелинейный слой. Вот примеры извстных нелинейных слоёв:

1. **ReLU**
Одна из самых распространённых функций активации
    
    $$
    f(x) = 
     \begin{cases}
       0, {x < 0}\\
       x, {x > 0}
     \end{cases}
    $$
    
    + Функция простая для вычисления, следовательно, быстрая
    
    - Обнуление отрицательных чисел может привести к затуханию градиента
    
2. **Sigmoid**
Одна из первых функций активации, но на данный момент почти не используется как нелинейность.
    
    $$
    \sigma(x) = \frac{1}{1 + \exp^{-x}}
    $$
    
    - Вычисление производной экспоненты вычислиительно сложная операция
    
    - Чем больше значение $x$ по модулю, тем более горизонтальным становится хвост функции. Производная такого хвоста стремится к 0, что может привести к затуханию градиента.
    
3. **LeakyReLU**
Небольшая модификация ReLU
    
    $$
    f(x) = 
     \begin{cases}
       0.1\cdot x, {x < 0}\\
       x, {x > 0}
     \end{cases}
    $$
    
    + Уменьшает вероятность затухания, так как не полностью обнуляет отрицательные значения
    

Тогда наша нейронная сеть будет выглядеть, например, таким образом: $y = ReLU(X\cdot W_1) \cdot W_2$

Следовательно, нейронная сеть - это комбинация различных слоёв, в которой линейность чередуется с нелинейностью. Но это не самое совершенное определенние, так как помимо нелинейности есть и другие слои, например dropout, который случайно обнуляет какие-то значения в векторе объекта.

Схематически нейронную сеть можно представить так:

![Снимок экрана 2023-11-27 в 00.36.05.png](%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B2%20%D0%BD%D0%B5%D0%B8%CC%86%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%20dda83f07ab524dc3ac8aa078c1785995/%25D0%25A1%25D0%25BD%25D0%25B8%25D0%25BC%25D0%25BE%25D0%25BA_%25D1%258D%25D0%25BA%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B0_2023-11-27_%25D0%25B2_00.36.05.png)

Как можно заметить, каждый элемент предыдущего слоя связан с каждым элементом следующего, поэтому слой и называется **полносвязным**. Слой в центре, промежуточный, называют **скрытым слоем**. Кроме этого, на рисунке результат работы модели - единственный $y$, но это не всегда так. Часто, особенно в языковых моделях, выход нейронной сети - многомерный. Это полезно в случаях, когда у нас есть большое количество возможных результатов, и нам нужно предсказать, какой из результатов наиболее вероятный. Например, в языковом моделировании нам нужно выбрать наиболее вероятное продолжение предложения, тогда в модели последний выходной слой будет состоять из N нейронов, где N - это количество слов в словаре.

## Обучение нейронной сети

Процесс обучения нейронной сети почти не отличается от обучения простой модели машинного обучения (которая, как мы поняли, ни что иное, как однослойная нейронная сеть). Но если в однослойной модели мы считаем **градиент** по единственной функции, то в многослойной модели мы сталкиваемся со сложной функцией, то есть результат одной функции, зависит от результата другой. Таким образом, у нас получается целая цепь функций, в которой мы должны изменять параметры. Процесс изменения параметров в такой цепи называется **обратным распространением ошибки (backpropagation)**. Также можно услышать выражение: *градиент течёт*, что как раз и описывает процесс подсчёта ошибки. Метод вычисления градиента называется **обратным**, потому что он считает производную от выхода модели к её входу. Если хочется глубже понять суть обратного распространения ошибки, можно прочитать [главу 7.6 учебника от Stanford](https://web.stanford.edu/~jurafsky/slp3/7.pdf).

### Функция потерь

Обычно языковые нейронные сети обучаются на предсказание слова или определённого тега слова из множества тегов. Самое простое решение, это каждому слову сопоставить какой-то номер и предсказывать на последнем слое одно число - номер этого слова. Однако словари языка очень велики и предсказывать номер от 1 до, например, 1000000 может быть очень трудной задачей. Чтобы этого избежать выходной слой имеет размерность по количеству слов в словаре или тегов из множества тегов, которые мы хотим проставлять (например, часть речи). 

Давайте представим языковую модель, которая выполняет задачу генерации текста. Тогда на каждом шаге модель должна определить, какой слово поставить. Тогда выходной вектор представляет собой набор чисел, где число на позиции $n$ соответствует уверенности модели, что на данном месте в предложении стоит слово $W_n$. Следовательно, мы стремимся к тому, чтобы верное слово для данной позиции имело наибольшее значение. Так как модель может предсказать любое число от $-\infty$ до $+\infty$, мы стремимся к наибольшему, но для обучении модели мы должны как-то ограничить это наибольшее. Простой способ это сделать - привести все числа к промежутку $[0;1]$, что будет означать *вероятность*, что данное слово стоит на позиции $n$. Тогда нужно, чтобы вероятность верного слова стремилась к 1.

Первый вопрос заключается в том, как сделать из чисел *вероятности*. Для этого используется функция softmax, где N - количество слов в словаре:

$$
softmax(x_i) = \frac{exp(x_i)}{\sum_{j=1}^N exp(x_j)}
$$

Экпонента в формуле используется для того, чтобы избежать отрицательных чисел, ведь вероятность не может быть меньше 0. 

Когда мы привели выходной вектор к вероятностному распределению, появляется второй вопрос: как эту информацию использовать для обучения? Вернёмся к тому, что наша задача приблизить вероятность верного слова к единице, то есть, чем больше разница между предсказанием модели и единицей, тем больше нужно штрафовать модель. Остальные слова при подсчёте ошибки нас не очень интересуют. Тогда на помощь приходи **кросс-энтропия (cross-entropy loss)**. Рассмотрим сначала кросс-энтропию для бинарного выхода модели (когда ответ имеет только два значения - 0 или 1).

$$
Loss_{CE} = -log(p(y|x)) = -[ylog(\hat{y}) + (1-y)log(1-\hat{y})]
$$

Если вероятность близка к 1, то ответ модели - 1, если близка к 0, то - 0. Тогда если верный ответ 1, то мы считаем логарифм от вероятности, предсказанной моделью в первом слагаемом, а второе обнуляется. Если же верный ответ 0, то первое слагаемое обнуляется (потому что $y=0$), а во втором мы считаем логарифм вероятности обратного события, мы хотим, чтобы вероятность была близка к нулю, следовательно, при вычитании из единицы наиболее близка к единице.

Приведём формулу к многоклассовому выходу:

 

$$
Loss_{CE} = -\sum_{i=1}^{N}y_ilog(\hat{y_{k}})
$$

В данной формуле, аналогично формуле бинарной кросс-энтропии, мы считаем ошибку только на таргете, то есть на том слове, у которого $y=1$, когда как для остальных слов слагаемое обнулится.

Посчитанные логарифмы будут отрицательными, так как их аргументами являются числа от 0 до 1. Чтобы следовать правилу “минимизации функции” перед суммой ставится минус, чтобы перевести сумму логарифмов к положительному числу.

### Проблема больших данных

Большинство современных моделей имеют огромное количество параметров. Миллионы или даже миллиарды. Для их обучения необходимо огромное количество данных, причем вектора этих данных также могут иметь большую размерность. Если все данные разом *скормить* модели, то память компьютера может лопнуть. Чтобы этого избежать, чаще всего модели обучают **батчами** (или по-русски их ещё называют **пакетами**). Простыми словами, это разделение всего множества объектов на списки равной длины. Тогда эпоха обучения начинает делиться на шаги: эпоха - это этап обучения на всех данных, шаг - этап обучения на одном батче. 

**Формально процесс можно расписать так:**

1. Берём случайный батч
2. Получаем предсказания модели на батче
3. Считаем лосс
4. Делаем шаг градиентного спуска
5. Записываем лосс в отдельный список
6. В конце эпохи считаем средний лосс по всем шагам, как обобщение ошибки по всем батчам на эпохе.

Таким образом, решается проблема памяти и проблема скорости. Батчи меньше занимают оперативной памяти во время обучения, а также на них быстрее считается градиент.

## Итог

Мы столкнулись с проблемами, которые не решаются простыми линейными моделями. Одним из способов решить подобные проблемы - это совместить несколько линейных слоёв, чтобы находить более глубокие связи в данных. Однако важно помнить, что два линейных слоя подряд равны одному линейному слою, поэтому нужно добавлять нелинейности. Помимо них есть ещё множество других слоёв, позволяющих улучшать работу нейронной сети. Но об этом немного позже:)

Также мы рассмотрели функцию потерь **кросс-энтропия**, которая используется для обучения моделей с большим количеством классов.